# Introduction to Motion

## Localization

- Representing motion and tracking objects in a video
- Uncertainty in robotic motion
- Histogram Filter
- Motion models and tracking the position of a self-driving car over time

## Simultaneous Localization and Mapping (SLAM)
- technique that allows autonomous vehicles to build up a model of the world
    while locating itself within that world. 

## Use of motion understanding by CV

- isolate moving pedestrian from a still background
- intelligent navigation system
- movement prediction models
- distinguishing behaviours in video like running vs walking 
-
One way to track objects over time and detect motion is by extracting certain
features and observing how they change from one frame to another. One such
method is optical flow.

## OPtical Flow
- used in tracking and motion analysis applications
- Assumptions:
  - Pixel intensities stay consistent between consecutive frames i.e. $I(x,y,t)
      = I(x+u, y+v, t+1)$. This equation is called brightness constancy
      assumption

      Using Taylor Series expansion,

      $I(x,y,t) = \frac{\partial I}{\partial x}u + \frac{\partial I}{\partial y}v + \frac{\partial I}{\partial t}1 + I(x,y,t)\\
       \frac{\partial I}{\partial x}u + \frac{\partial I}{\partial y}v = - \frac{\partial I}{\partial t} $
  - Neighboring pixels have similar motion.
- Tracks interesting features like corners
- Hand gesture recognition, tracking vehicle movement, eye tracking, autonomous
    vehicle navigation
- Uses motion vector $(u,v)$

## Motion vector

Given various frames,

- First find the keypoints using Harris/ORB/Shi-Tomasi detectors.
- Then calculate the optical flow between this image frame (frame 1) and the next frame (frame 2), using OpenCV's calcOpticalFlowPyrLK
